{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scskalicky/LING-226-vuw/blob/main/08_dictionaries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffOVxu5Nb6m9"
      },
      "source": [
        "# Python Dictionaries\n",
        "\n",
        "In a prior lesson we looked at using the `nltk.FreqDist()` function, which returns a specialised version of a built-in Python data type known as a `dictionary`. In this notebook we will cover how to create and use dictionaries in more depth. \n",
        "\n",
        "We have already looked at using lists as a way to store data. A list is like a bucket which you can toss all of your stuff in. A dictionary imposes much more order than a list, and is ultimately more useful for many of the linguistic analyses we would like to perform.\n",
        "\n",
        "A Python dictionary works in a similar manner to book dictionaries, where you look up the meaning of words. You first think of the word you want to look up, find it, then read the entry. A Python dictionary words the same way — you query the dictionary for a specific entry, and instead of returning the entry itself, the dictionary returns information associated with that entry.\n",
        "\n",
        "Python dictionaries store information using `key:value` pairs. The `nltk.FreqDist()` function returns a dictionary where the `key` is the thing that was counted, and the `value` is the frequency of that thing. \n",
        "\n",
        "To create an empty Python dictionary, we can use `dict()`. To add entries to the dictionary, we use the square bracket notation `[]` after the name of the dictionary, then use `=` to assign the value. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krxrmi7Yb5J8"
      },
      "outputs": [],
      "source": [
        "# initial creation of a dictionary\n",
        "species = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaDiE2BkdUMx"
      },
      "outputs": [],
      "source": [
        "# adding a key and a value\n",
        "species['dog'] = 'canine'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOoEa0k4dWhC"
      },
      "outputs": [],
      "source": [
        "# calling a key to get a value\n",
        "species['dog']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is0uht6RdotJ"
      },
      "source": [
        "You can also choose to pre-populate a dictionary using curly braces and colons:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thQDK3imdYXx"
      },
      "outputs": [],
      "source": [
        "# You can create using curly braces\n",
        "species = {'dog': 'canine', 'cat': 'feline'}\n",
        "\n",
        "species['cat']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EqBMhF3t_Lw"
      },
      "outputs": [],
      "source": [
        "species['dog']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaaEvvFLd06G"
      },
      "source": [
        "## Rules for dictionary keys\n",
        "\n",
        "- Dictionary keys need to be *immutable* values which include strings, integers, booleans, tuples, and so on. This mostly means that you can't use a list as a dictionary key\n",
        "- much like a real dictionary, each key can only occur one time in a dictionary\n",
        "- the value associated with a dictionary key can be almost anything, including another dictionary, which can then contain other dictionaries...\n",
        "  - if you manually add a value, you might overwrite what is already there. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjK1tIfIfTfx"
      },
      "outputs": [],
      "source": [
        "# create an empty dictionary\n",
        "temp_dict = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKcAHGfRfVtw"
      },
      "outputs": [],
      "source": [
        "# add a string as a key\n",
        "temp_dict['one'] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpJhm4ZQfaki"
      },
      "outputs": [],
      "source": [
        "# look at the dictionary\n",
        "temp_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNP6zD0EffB5"
      },
      "outputs": [],
      "source": [
        "# add a number as a key\n",
        "temp_dict[1] = 'one'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghMV3y59fiLD"
      },
      "outputs": [],
      "source": [
        "# look at the dictionary\n",
        "temp_dict[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgZRGAvpfk7o"
      },
      "outputs": [],
      "source": [
        "# update our dictionary:\n",
        "temp_dict['one'] = 'ONE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgGANdrgftyp"
      },
      "outputs": [],
      "source": [
        "# we have overwritten the value, because they key can only exist once. \n",
        "temp_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ire-A1QPfzZb"
      },
      "outputs": [],
      "source": [
        "# try adding a list as a key, you get an error.\n",
        "temp_dict[['one', 'two']] = [1,2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNT5xL_Zji06"
      },
      "source": [
        "Crucially, you should notice an important difference in how `[]` are used in dictionaries versus strings. While `[]` indexes specific *locations* in a string or list, the `[]` indexes specific *keys* in a dictionary. This means you do not need to worry about the ordering of a dictionary's keys, but instead the values of the keys themselves. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzsekNIWumoW"
      },
      "source": [
        "## **Your Turn**\n",
        "\n",
        "Take this moment to make some dictionaries of your own. Start simple, such as a dictionary containing first and last names, or a dictionary containing names and phone numbers of people you know. \n",
        "\n",
        "Explore creating an empty dictionary and then adding values, as well as creating a dictionary using curly braces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6xOC9rjuWZO"
      },
      "outputs": [],
      "source": [
        "# make some dictionaries. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgvWKcLjf8am"
      },
      "source": [
        "## Searching dictionaries\n",
        "\n",
        "Because dictionaries do not use indexing in the same way as strings and lists, we need to explore some alternative methods for looping and searching through dictionaries. \n",
        "\n",
        "Below, I will initalise a simple translation dictionary between English and te reo Māori. They `keys` are the English version, and the `values` are the Māori."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0kiivLEgKCe"
      },
      "outputs": [],
      "source": [
        "# create a translation dictionary\n",
        "eng2mri = {'one': 'tahi','two': 'rua', 'three': 'toru', 'four': 'whā', 'five': 'rima', 'six': 'ono', 'seven': 'whitu', 'eight': 'waru', 'nine': 'iwa', 'ten': 'tekau'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzbKXwuokQVl"
      },
      "outputs": [],
      "source": [
        "# test if it works\n",
        "eng2mri['ten']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_-5RWuNkqcc"
      },
      "source": [
        "To see the entire dictionary, we can use the `.items()` dictionary method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E91paznYktQl"
      },
      "outputs": [],
      "source": [
        "# what are they key:value pairs in this dictionary?\n",
        "eng2mri.items()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMiXoMs_0vcj"
      },
      "source": [
        "Altneratively, we can inspect all of the entries in a dictionary by using the `.keys()` method...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYSjjy-xkcsB"
      },
      "outputs": [],
      "source": [
        "# what are the keys of this dictionary?\n",
        "eng2mri.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLbo-BmukiKy"
      },
      "source": [
        "...or we can inspect all of the values using the `.values()` method. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdoM-45GkkwY"
      },
      "outputs": [],
      "source": [
        "# what are the values of this dictionary?\n",
        "eng2mri.values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM_rNT7jk1e3"
      },
      "source": [
        "Now that we know how to access the keys of a dictionary, we can start to search through dictionaries using loops. For example, if we wanted to loop through each entry of a dictionary, we could use:\n",
        "\n",
        "```\n",
        "for key in dict.keys():\n",
        "  print(key)\n",
        "```\n",
        "\n",
        "While getting the keys is useful to know what is inside the dictionary, we commonly also want to do something with the values associated with the key. So, we could adjust our for loop to loop over the keys, but then return the value associated with the key, rather than the key itself:\n",
        "\n",
        "```\n",
        "for key in dict.keys()\n",
        "  print(dict[key])\n",
        "```\n",
        "\n",
        "Maybe this seems a bit confusing in the abstract, compare the for loops below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MR-_9-d_v8Q"
      },
      "outputs": [],
      "source": [
        "# print all of the keys\n",
        "for key in eng2mri.keys():\n",
        "  print(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZMYccJI-GHK"
      },
      "outputs": [],
      "source": [
        "# now print all of the values by using the key as an index in the loop\n",
        "for key in eng2mri.keys():\n",
        "  print(eng2mri[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw6HZemO_wff"
      },
      "outputs": [],
      "source": [
        "# could also print both the key and the value:\n",
        "for key in eng2mri.keys():\n",
        "  print(key, eng2mri[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdi3yFcY6x3l"
      },
      "outputs": [],
      "source": [
        "# the same thing but with some fancier print formatting\n",
        "for key in eng2mri.keys():\n",
        "  print(f'{key} = {eng2mri[key]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_dfCR9oIeRn"
      },
      "source": [
        "And, we could actually reverse the order just by swapping the variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGype4Md7j-H"
      },
      "outputs": [],
      "source": [
        "# swap the order\n",
        "for key in eng2mri.keys():\n",
        "  print(f'{eng2mri[key]} = {key}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo3hs8OhIpwS"
      },
      "source": [
        "## Adding conditions to our search\n",
        "\n",
        "Let's create some conditional logic to spruce up our searches. For example, we could look at each translation pair and print whichever of the two words are the longest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DczSCrNL7yF8"
      },
      "outputs": [],
      "source": [
        "# start a loop\n",
        "for key in eng2mri.keys():\n",
        "  # if value is longer than key:\n",
        "  if len(eng2mri[key]) >= len(key):\n",
        "    print(eng2mri[key])\n",
        "  \n",
        "  else:\n",
        "    print(key)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1WTbH1Qtkh2"
      },
      "source": [
        "Now let's consider another dictionary of population of countries in Oceania. We can use conditional logic to provide some evaluations of the values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Snr5P60-c_cN"
      },
      "outputs": [],
      "source": [
        "oceania = {'Tokelau': 1499, 'Norfolk Island': 1748, 'Federated States of Micronesia': 103000, 'Nauru': 10084, 'New Zealand': 4795886, 'Tonga': 100651, 'Tuvalu': 10640, 'Niue': 1611, 'Cook Islands': 18100, 'Samoa': 199052, 'Marshall Islands': 55500, 'Wallis and Futuna': 11700, 'French Polynesia': 275918, 'Australia': 25710853, 'American Samoa': 56700, 'Palau': 21000, 'Papua New Guinea': 8558800, 'New Caledonia': 278500, 'Northern Mariana Islands': 56200, 'Vanuatu': 304500, 'Kiribati': 120100, 'Fiji': 896445, 'Pitcairn Islands': 50, 'Guam': 172400, 'Solomon Islands': 667044}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Znt6YGw8Uf5s"
      },
      "source": [
        "Let's first print out each country and its population:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rn5XfFA8VVV"
      },
      "outputs": [],
      "source": [
        "for key in oceania.keys():\n",
        "  print(f'the population of {key} is {oceania[key]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I4-EpRQUk4c"
      },
      "source": [
        "Let's do this alphabetically by employing the `sorted()` function around the keys:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeI6E1WT8oCL"
      },
      "outputs": [],
      "source": [
        "for key in sorted(oceania.keys()):\n",
        "  print(f'the pop of {key} is {oceania[key]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_3ngpgdkcXv"
      },
      "source": [
        "\n",
        "Now let's consider sorting our population sizes into different catgories, such as these:\n",
        "\n",
        ">*large* = more than 1,000,000 people\n",
        "\n",
        "> *medium* = 100,000 to 1,000,000 people\n",
        "\n",
        "> *small* = 10,000 to 100,000 people\n",
        "\n",
        "> *very small* = less than 10,000\n",
        "\n",
        "Using these criteria, we can adapt the previous `for` loop so that it returns statements like this:\n",
        "\n",
        "```\n",
        "The population of Australia is big: 25710853.\n",
        "```\n",
        "\n",
        "We can do this with a series of elif statements.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTnVLxbs87FA"
      },
      "outputs": [],
      "source": [
        "# loop through the sorted keys\n",
        "for key in sorted(oceania.keys()):\n",
        "  # consider different sizes and categories\n",
        "  if oceania[key] < 10000:\n",
        "    size = 'very small'\n",
        "  elif oceania[key] > 10000 and oceania[key] < 100000:\n",
        "    size = 'small'\n",
        "  elif oceania[key] > 100000 and oceania[key] < 1000000:\n",
        "    size = 'medium'\n",
        "  else:\n",
        "    size = 'large'\n",
        "\n",
        "  print(f'the pop of {key} is {size}! - {oceania[key]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW8kpZnfgUN_"
      },
      "source": [
        "Let's take the total population of Oceania to be 41,909,794. \n",
        "\n",
        "We can continue adapting the previous `for` loop to return statements like this:\n",
        "\n",
        "```\n",
        "The population of Australia is big: 25710853, which is _____ percent of the total population of Oceania. \n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1zbmLXxt7LE"
      },
      "outputs": [],
      "source": [
        "# total population of Oceania\n",
        "total_pop = 41909794\n",
        "\n",
        "# loop through the sorted keys\n",
        "for key in sorted(oceania.keys()):\n",
        "  # consider the size and assign a value\n",
        "  # can you think of a different way to do this? \n",
        "  if oceania[key] < 10000:\n",
        "    size = 'very small'\n",
        "  elif oceania[key] > 10000 and oceania[key] < 100000:\n",
        "    size = 'small'\n",
        "  elif oceania[key] > 100000 and oceania[key] < 1000000:\n",
        "    size = 'medium'\n",
        "  else:\n",
        "    size = 'large'\n",
        "  \n",
        "  # calculate population percentage and round to 3 decimals. \n",
        "  pop_perc = round((oceania[key] / total_pop) *100, 3)\n",
        "\n",
        "  print(f'the pop of {key} is {size}! - it is {oceania[key]}, which is {pop_perc}% of Oceania!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9rhAcuXvAJ3"
      },
      "source": [
        "# Building more complex dictionaries\n",
        "\n",
        "The dictionaries used so far have all included single `key:value` pairs. We can include more complex information in our dictionaries. For example, we could create a dictionary which stores lexical information about different texts — this is an ideal way to contain information about language because a dictionary can be continuously updated with new texts and new features. \n",
        "\n",
        "Let's start with two small texts. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1KwUqhKxk7_"
      },
      "outputs": [],
      "source": [
        "whale = \"\"\"The sea was angry that day, my friends - like an old man trying to send back soup in a deli. \n",
        "I got about fifty feet out and suddenly, the great beast appeared before me. \n",
        "I tell you, he was ten stories high if he was a foot. \n",
        "As if sensing my presence, he let out a great bellow.\"\"\"\n",
        "\n",
        "the_kramer = \"\"\"I sense great vulnerability. A man-child crying out for love. An innocent orphan in the post-modern world.\n",
        "I see a parasite. A sexually depraved miscreant who is seeking only to gratify his basest and most immediate urges.\n",
        "His struggle is man's struggle. He lifts my spirit.\n",
        "He is a loathsome, offensive brute. Yet I can’t look away.\n",
        "He transcends time and space.\n",
        "He sickens me.\n",
        "I love it.\n",
        "Me too.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8V-B41-yk0C"
      },
      "source": [
        "Let's create a dictionary in which the keys will represent each of these texts. The values of each key will be a *new* dictionary which contains information about the text. The first piece of information will be the text itself:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqNBGVf8yrUA"
      },
      "outputs": [],
      "source": [
        "# create a dictionary named sf_dict with one key(whale)\n",
        "# the value for the key is another dictionary, with one key (text) and the value is the string associated with whale (above)\n",
        "sf_dict = {'whale': {'text': whale} }\n",
        "sf_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3csMwoJzaku"
      },
      "outputs": [],
      "source": [
        "# we can index the text by using [key][key]\n",
        "# this is asking first to look at the key \"whale\", then at the key \"text\"\n",
        "sf_dict['whale']['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ginnOFNGzout"
      },
      "source": [
        "Now that we've added one text to the dictionary, let's add the second:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqgM2J8EznLm"
      },
      "outputs": [],
      "source": [
        "sf_dict['the_kramer'] = {'text': the_kramer}\n",
        "sf_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_p9apUGy8Rc"
      },
      "source": [
        "Now that we have our texts stored in the same dictionary with their own sub dictionaries, let's start performing some actions. Let's start simple and include the total number of words per text using `len()` and `.split()`.\n",
        "\n",
        "Now, we could independently calculate these values and then add them to the dictionary manually.\n",
        "\n",
        "Or, we could initiate a for loop which simultaneously loops over the dictionary and creates the new values for us in one go. \n",
        "\n",
        "In the following cell, I do this in one line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sznj7wK-0AXG"
      },
      "outputs": [],
      "source": [
        "# add total length of text to the dictionary\n",
        "for key in sf_dict.keys():\n",
        "  sf_dict[key]['word_length'] = len(sf_dict[key]['text'].split())\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWK-zzXVnNSl"
      },
      "source": [
        "There's a lot going on in that one line, so I have created an annotation which can help unpack what is going on:\n",
        "\n",
        "<img src = https://i.imgur.com/202gE2K.png>\n",
        "\n",
        "Basically, we are first selecting an entry in our top level dictionary, and because that will return a second dictionary, we then select an entry from *that* dictionary. If the annotated screen shot above doesnt quite help, perhaps this sketch of the structure is more straightforward:\n",
        "\n",
        "```\n",
        "top-level dictionary (sf_dict)\n",
        "  - entry 1 (whale)\n",
        "    - whale dictionary\n",
        "      - entry 1 (text)\n",
        "      - entry 2 (word_length)\n",
        "  - entry 2 (the_kramer)\n",
        "    - the_kramer dictionary\n",
        "      - entry 1 (text)\n",
        "      - entry 2 (word_length)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFxZY8zH0xqw"
      },
      "outputs": [],
      "source": [
        "# we can see the results of our new variable by calling it, for each text...\n",
        "sf_dict['whale']['word_length']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O7hpKpH0wRS"
      },
      "outputs": [],
      "source": [
        "sf_dict['the_kramer']['word_length']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n_2MGuWoftH"
      },
      "source": [
        "Ideally you can see how running a single loop over a dictionary and performing operations on the information in that dictionary allows for a one-stop shop of a data container which can be expanded to include as many pieces of information as one might like. \n",
        "\n",
        "Let's extend the above example and create a dictionary of lexical information for our texts. For each text, we will report:\n",
        "\n",
        "- the total number of words according to `.split()`\n",
        "- the total number of tokens according to `nltk.word_tokenize()`\n",
        "- the resulting TTR using `.split()` versus `nltk.word_tokenize()`\n",
        "- the top 5 most frequent words using `nltk.FreqDist()` and `.split()` \n",
        "- the top 5 most frequent words using `nltk.FreqDist()` and `nltk.word_tokenize()`\n",
        "\n",
        "Sounds like a lot, right? You should know how to do each of these operations - it's just a matter of adding them to the for loop that we've already seen above. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5knG2GeYpsfQ"
      },
      "outputs": [],
      "source": [
        "# load in required nltk resources.\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nsyPUVnr_zU"
      },
      "outputs": [],
      "source": [
        "# let's delete the word_length entry we made above\n",
        "del sf_dict['whale']['word_length']\n",
        "del sf_dict['the_kramer']['word_length']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-W4mxNM3pXMb"
      },
      "outputs": [],
      "source": [
        "# Expand the for loop to calculate more features:\n",
        "\n",
        "for key in sf_dict.keys():\n",
        "  # number of words according to .split()\n",
        "  sf_dict[key]['num_split_tokens'] = len(sf_dict[key]['text'].split())\n",
        "\n",
        "  # number of words according to nltk.word_tokenize\n",
        "  sf_dict[key]['num_nltk_tokens'] = len(nltk.word_tokenize(sf_dict[key]['text']))\n",
        "\n",
        "  # ttr from split\n",
        "  sf_dict[key]['split_ttr'] = len(sf_dict[key]['text'].split()) / len(set(sf_dict[key]['text'].split()))\n",
        "\n",
        "  # ttr from nltk tokens\n",
        "  sf_dict[key]['nltk_tokens_ttr'] = len(set(nltk.word_tokenize(sf_dict[key]['text']))) / len(nltk.word_tokenize(sf_dict[key]['text']))\n",
        "\n",
        "  # top 5 most frequent words using .split()\n",
        "  sf_dict[key]['split_five_most_frequent'] = nltk.FreqDist(sf_dict[key]['text'].split()).most_common(5)\n",
        "\n",
        "  # top 5 most frequent words using nltk tokenz\n",
        "  sf_dict[key]['nltk_five_most_frequent'] = nltk.FreqDist(nltk.word_tokenize(sf_dict[key]['text'])).most_common(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZHaza4UpUzc"
      },
      "outputs": [],
      "source": [
        "# now look at the information we have about the text\n",
        "sf_dict['whale']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz7Ibk4Pqjta"
      },
      "outputs": [],
      "source": [
        "sf_dict['the_kramer']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zm15ZHPsknD"
      },
      "source": [
        "##**Your Turn**\n",
        "\n",
        "Compare the output from the two texts above. Think about the difference you see between the `.split()` and `nltk.word_tokenize()` approaches. \n",
        "\n",
        "- Do you remember why these function are providing different results?\n",
        "- What do you notice about the frequency results? Is there any pre-processing we might want to do, and if so, which results would be changed as a result of different pre-processing? "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMixYnbGtOH9wImhpZfgEbF",
      "collapsed_sections": [],
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "44a9cdcbdccbf05a880e90d2e6fe72470baab4d1b82472d890be0596ed887a6b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
