{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scskalicky/LING-226-vuw/blob/main/23a_WordNet_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlXd3EH-XKZC"
      },
      "source": [
        "# WordNet Challenge\n",
        "\n",
        "> *(this was a marked assignment in 2021. We are going to use it as practice now)*\n",
        "\n",
        "Today I am going to present you with a program or challenge to complete during the workshop. You can work together or alone, up to you. In the instructions below, I will ask you to create two different functions designed to find different pieces of information from WordNet.\n",
        "\n",
        "Objectives/Skills:\n",
        "\n",
        "- creating helper functions to serve a larger function\n",
        "- using one set of global variables for all functions\n",
        "- practice using parts of speech\n",
        "- practice using wordnet\n",
        "- further practice tokenizing and tagging text (using built-in NLTK functions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f7DKNt3DnXR"
      },
      "source": [
        "# **Sense Finder**\n",
        "\n",
        "The goal of `sense_finder()` is to do essentially the same thing as the WordNet printer function from a previous notebook. This function is a bit different because it allows you to control the number of senses which will be returned.\n",
        "\n",
        "1. Define a function named `sense_finder()`.\n",
        "  - This function will take two arguments: `word` and `senses`.\n",
        "  - Set the default value of `senses` = 3.\n",
        "\n",
        "2. In the body of `sense_finder()`, create two variables: `noun_synsets` and `verb_synsets`.\n",
        "  - Set these variables to be the result of calling `wn.synsets()` on the `word` argument for nouns or verbs, respectively.\n",
        "  \n",
        "    - use the `pos = wn.NOUN` or `pos = wn.VERB` arguments in `wn.synsets` to request noun/verb synsets (you could also use `pos = 'n'` or `pos = 'v'`)\n",
        "\n",
        "3. Then, use an `if statement` to check whether `noun_synsets` exists or is empty.\n",
        "  - If `noun_synsets` is empty, do nothing.\n",
        "  - If `noun_synsets` is *not* empty, check whether the length of `noun_synsets` is greater than or equal to the value of `senses`\n",
        "  - if `noun_synsets` is greater than or equal to the value of `senses`, print a message stating something to the effect of: `\"The noun meanings of {word} are {noun_synsets}\"`\n",
        "    - Then, loop through each synset from `noun_synsets` and print the `synset.definition()`. Again, use some sort of informative print statement, such as `\"The definition of {synset} is {synset.definition()}`\n",
        "      - ***However***, the loop should only loop through a number of synsets which are equal to `senses`. In other words, a synset might have 10 total entries, but if `senses` == 3, the program should only print the first 3. To do this, the for loop should slice `noun_synsets` using `senses`\n",
        "        - you could use `noun_synsets[:senses]`\n",
        "  - if the length of `noun_synsets` is *not* greater than or equal to `senses`, then loop through each synset and print their `synset_definition()` (i.e., without slicing based on senses, since the total amount is lower than the requested number of senses)\n",
        "  - if include an `else` statement to inform the user if no noun senses exist.\n",
        "\n",
        "4. After the set of `ifs` and `else` for the noun synsets, create another `if` statement (**not** an `elif`) which does the same thing for `verb_synsets`\n",
        "\n",
        "5. Create a final `if statement` which triggers if `word` has no noun synsets *and* no verb synsets. This condition should print a message explaining there are no synsets for the given word.\n",
        "\n",
        "5. Test your function with a variety of words\n",
        "\n",
        "\n",
        "See my sample output below for what kind of output you might expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AezHDzJsx0-"
      },
      "outputs": [],
      "source": [
        "# download and import wordnet\n",
        "\n",
        "import nltk\n",
        "nltk.download(['wordnet', 'omw-1.4'])\n",
        "\n",
        "from nltk.corpus import wordnet as wn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH7dA0YOjgpT"
      },
      "source": [
        "## Sample output for `sense_finder()`\n",
        "\n",
        "Your print statements do not need to match mine, and I encourage you to improve upon or tweak my instructions as long as you can get the desired output!\n",
        "\n",
        "\n",
        "1. Program limits senses to whatever is in the function, even though both noun and verb have more than one sense for this word\n",
        "\n",
        "```\n",
        "sense_finder('comb', 1)\n",
        "========================\n",
        " the NOUN meanings of comb are :\n",
        " [Synset('comb.n.01'), Synset('comb.n.02'), Synset('comb.n.03'), Synset('comb.n.04'), Synset('comb.n.05')]\n",
        "Synset('comb.n.01')\n",
        " a flat device with narrow pointed teeth on one edge; disentangles or arranges hair\n",
        "========================\n",
        " The VERB meanings of comb are :\n",
        " [Synset('comb.v.01'), Synset('comb.v.02'), Synset('comb.v.03')]\n",
        "Synset('comb.v.01')\n",
        " straighten with a comb\n",
        "```\n",
        "\n",
        "2. Program works even when word has fewer synsets than requested\n",
        "\n",
        "```\n",
        "sense_finder('basketball', 5)\n",
        "========================\n",
        " the NOUN meanings of basketball are :\n",
        " [Synset('basketball.n.01'), Synset('basketball.n.02')]\n",
        "Synset('basketball.n.01')\n",
        " a game played on a court by two opposing teams of 5 players; points are scored by throwing the ball through an elevated horizontal hoop\n",
        "\n",
        "Synset('basketball.n.02')\n",
        " an inflated ball used in playing basketball\n",
        "```\n",
        "\n",
        "3. Program works even when the word has no verb or noun synsets\n",
        "\n",
        "```\n",
        "sense_finder('wonderful')\n",
        "========================\n",
        " Sorry, no noun senses for wonderful\n",
        "========================\n",
        " Sorry, no verb senses for wonderful\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvtrdf1EkpFw"
      },
      "source": [
        "## Reflection for `sense_finder()`\n",
        "\n",
        "\n",
        "Try these words in your program with the default values for `senses`.\n",
        "\n",
        "1. google\n",
        "2. xerox\n",
        "3. bing\n",
        "4. apple\n",
        "5. phone\n",
        "6. brush\n",
        "\n",
        "**Discussion**\n",
        "\n",
        "Test your program on these suggested words and more (choose your own words which straddle the line between noun and verb)\n",
        "\n",
        "- Do you think the senses provided make...sense?\n",
        "- How could one use this information for processing text?\n",
        "  - For example, could this program be adapted to guess the meaning of a word in a sentence?\n",
        "  - What other information might you want in order to do so?\n",
        "\n",
        "- What other information could we get from WordNet which might be useful/interesting for text analysis?\n",
        "\n",
        "- Programatically, this program repeats print statements twice for nouns and verbs - what could be done to reduce this repetition?\n",
        "\n",
        "- What other tweaks or efficiencies can you make to the program?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsI54B6NDgwT"
      },
      "source": [
        "# Nouny Verbs\n",
        "\n",
        "\n",
        "Now, let's write a function which uses part of speech tags and incorporates our new `sense_finder()` function!\n",
        "\n",
        "\n",
        "You'll need these resources:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NiHxk1pRKCz"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(['punkt', 'averaged_perceptron_tagger', 'stopwords'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew7RmGA9yfh6"
      },
      "source": [
        "**Code Cell 1**\n",
        "\n",
        "Refer to this resource: [Penn Treebank POS tags](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)\n",
        "\n",
        "- create a global variable named `noun_tags` which includes the POS tags for `Noun, singular or mass` and `Noun, plural`\n",
        "- create a global variable named `verb_tags` which is a list including all Penn Treebank POS tags for verbs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldDZkrxFyeaQ"
      },
      "outputs": [],
      "source": [
        "# noun_tags and verb_tags here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdZ9M8omGH7i"
      },
      "source": [
        "**Code Cell 2**\n",
        "\n",
        "Define a function named `calc_tag_frequency()` which takes a single argument, `pair`\n",
        "\n",
        "```\n",
        "\n",
        "calc_tag_frequency(pair)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "- in the body of the function, create a variable named `noun_freq`.\n",
        "  - Set the value of the `noun_freq` variable to be the result of calling `.freq('N')` on `pair`\n",
        "\n",
        "- make another variable named `verb_freq` and set the value to be the result of calling `.freq('V')` on `pair`\n",
        "\n",
        "- using a single line, `return` two values:\n",
        "  - `noun_freq`\n",
        "  - `verb_freq`\n",
        "\n",
        "- the final return statement would look something like this:\n",
        "\n",
        "    - `return a, b`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTM6pQEq6RHk"
      },
      "outputs": [],
      "source": [
        "# define `calc_tag_frequency()` here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqOb-OPPOitQ"
      },
      "source": [
        "**Code Cell 3**\n",
        "\n",
        "1. Define a function named `nouny_verbs()` which takes two arguments: `text` and `senses`.\n",
        "  - Set the default value of `senses` to 3.\n",
        "\n",
        "2. Inside the function:\n",
        "\n",
        "  - create a conditional statement to check whether `text` is a `str`. If not, print a message to the user asking for a string and exit the program.\n",
        "\n",
        "  - create a variable named `tokens` which is the result of calling `nltk.word_tokenize()` on `text`, taking care to also lowercase the text before it is tokenized.\n",
        "\n",
        "  - create a variable `tagged` which is the result of calling `nltk.pos_tags()` on `tokens`\n",
        "\n",
        "  - create a variable `nouns_verbs` which is the result of a list comprehension. This list should include `(word, tag)` pairs from `tagged` that have POS tags in `noun_tags` or `verb_tags`. At the same time, slice out only the first element of `tag` (this will mean the tag will become either 'N' or 'V'). The goal is to only include `(word, tag)` pairs in which the tag is a noun or verb, while retaining only the `N` or `V` of the tag.\n",
        "\n",
        "  > *hint: use `[(word, tag[0]) for word, tag in ... if tag in ... or tag in ...]`*\n",
        "\n",
        "- create a `nltk.ConditionalFreqDist()` object named `tagged_cfd` which is a conditional frequency distribution of `nouns_verbs` (*you simply need to pass `noun_verbs` to `nltk.ConditionalFreqDist()`*)\n",
        "\n",
        "- now, after creating those objects, initiate a `for loop`, iterating through each word of `tagged_cfd`\n",
        "  \n",
        "  - hint: loop through the `.conditions()` method of `tagged_cfd` using something like: `for word in tagged_cfd.conditions():`  \n",
        "\n",
        "\n",
        "- Inside the loop, first check whether the word at least one \"N\" and \"V\" pos tag as part of its value in `tagged_cfd`\n",
        "  - To do this, you can write a conditionAL statement which checks whether the length of `tagged_cfd[word]['N']` and `tagged_cfd[word]['V']` are both greater than 0\n",
        "  - the goal is the `if` condition will only evaluate `True` if the word has at least one `N` and `V` tags.\n",
        "\n",
        "- If the word has both `N` and `V` tags, then create two variables, `noun_freq` and `verb_freq` and set them `=` to calling `calc_tag_frequency()` on the current word from `tagged_cfd`\n",
        "  - hint: `noun_freq, verb_freq = calc_tag_frequency(tagged_cfd[word])`\n",
        "    - this will work because `calc_tag_frequency()` is designed to return two values\n",
        "\n",
        "- Create a new variable called `total_frequency` which is the `sum()` of `noun_freq` and `verb_freq`\n",
        "\n",
        "- Create two variables `noun_percent` and `verb_percent`, each of which is the percentage of how nouny and how verby the word is\n",
        "  - to do this, divide `noun_freq` and `verb_freq` by `total_freq`\n",
        "\n",
        "- Now, write a conditional statement which checks whether both `noun_freq` and `verb_freq` are both higher than .33.\n",
        "\n",
        "    - If yes, classify the word as a nouny_verb. Run `sense_finder()` on the word to look at the different senses.\n",
        "\n",
        "      - Also, print out the percentages of noun/verb for the word\n",
        "\n",
        "\n",
        "- **Challenge** customize the function to perform different tasks should the work be classified as more nouny, more verby, or equally nouny and verby.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTbg6DyaOsII"
      },
      "source": [
        "## Sample output for `nouny_verb()`\n",
        "\n",
        "\n",
        "```\n",
        "found a nouny-verb! contact\n",
        "Noun Frequency: 0.5\n",
        "Verb Frequency: 0.5\n",
        "=========================\n",
        " The NOUN meanings of contact are:\n",
        "\n",
        "Synset('contact.n.01')\n",
        " close interaction\n",
        "\n",
        "Synset('contact.n.02')\n",
        " the act of touching physically\n",
        "\n",
        "Synset('contact.n.03')\n",
        " the state or condition of touching or of being in immediate proximity\n",
        "\n",
        "=========================\n",
        " The VERB meanings of contact are:\n",
        "\n",
        "Synset('reach.v.04')\n",
        " be in or establish communication with\n",
        "\n",
        "Synset('touch.v.05')\n",
        " be in direct physical contact with; make contact\n",
        "\n",
        "found a nouny-verb! thinking\n",
        "Noun Frequency: 0.4\n",
        "Verb Frequency: 0.6\n",
        "=========================\n",
        " The NOUN meanings of thinking are:\n",
        "\n",
        "Synset('thinking.n.01')\n",
        " the process of using your mind to consider something carefully\n",
        "\n",
        "=========================\n",
        " The VERB meanings of thinking are:\n",
        "\n",
        "Synset('think.v.01')\n",
        " judge or regard; look upon; judge\n",
        "\n",
        "Synset('think.v.02')\n",
        " expect, believe, or suppose\n",
        "\n",
        "Synset('think.v.03')\n",
        " use or exercise the mind or one's power of reason in order to make inferences, decisions, or arrive at a solution or judgments\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyVLU31R1QSZ"
      },
      "source": [
        "## Reflection for `nouny_verbs()`\n",
        "\n",
        "Test `nouny_verbs` on a few texts of your choice. This is a good opportunity to bring in your own texts, but you could also use some built-in nltk texts. Carefully observe the output, considering whether the ambiguity raised by words tagged equally as verbs/nouns is reconciled by WordNet.\n",
        "\n",
        "- How well is the program performing? Are there some results that don't seem to make sense?\n",
        "\n",
        "- What sorts of preparation to the text should be done further?\n",
        "\n",
        "- Would it make sense to limit the Wordnet information in some manner?\n",
        "\n",
        "- Conceptually, what could be done to improve this program?\n",
        "\n",
        "- What uses might a program like this have for NLP or other fields of research/industry?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "44a9cdcbdccbf05a880e90d2e6fe72470baab4d1b82472d890be0596ed887a6b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}