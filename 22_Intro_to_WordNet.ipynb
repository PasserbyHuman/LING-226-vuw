{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scskalicky/LING-226-vuw/blob/main/22_Intro_to_WordNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shvEIek2pAaJ"
      },
      "source": [
        "# What do words mean?\n",
        "\n",
        "## *Introduction to Wordnet*\n",
        "\n",
        "This notebook will introduce you to the English *WordNet*, which is a database of word associations. Of all the topics / resources we can work with in NLTK, I think WordNet may be the most interesting. That's because WordNet is trying to get at something we have not directly addressed up to this point — capturing the *meaning* of English words computationally. WordNet tries to capture such information by modelling (1) different senses associate with words and (2) relationships among those senses / words to other senses /words.\n",
        "\n",
        "\n",
        "As such, WordNet is a fantastic resource for delving deeper into lexical information, in particular how words in English relate to one another. You can [use wordnet online](http://wordnetweb.princeton.edu/perl/webwn), which might help you conceptually understand the way that wordnet is organised and how NLTK has been used to access the wordnet information. The [Wikipedia page](https://en.wikipedia.org/wiki/WordNet) for WordNet also includes a good deal of background and discussion (although you may want to read it after going through this notebook).\n",
        "\n",
        "NLTK includes WordNet as a resource, and is just a matter of downloading and importing the necessary resources.\n",
        "\n",
        "> *You may also want to explore using `help(wn)` (after you have imported it)*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD7_JSZ-qidQ"
      },
      "outputs": [],
      "source": [
        "# load in wordnet as wn\n",
        "import nltk\n",
        "nltk.download(['wordnet', 'omw-1.4'])\n",
        "from nltk.corpus import wordnet as wn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOJlJkJWP-CW"
      },
      "source": [
        "## Synsets\n",
        "\n",
        "\n",
        "In WordNet, words are organised into what are known as `synsets`, and these synsets represent the key objects you work with when using WordNet. You can search which synsets are associated with different words using the `synsets()` function.\n",
        "\n",
        "Simply pass the word as a string to the function.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MkFru_0GcNK"
      },
      "outputs": [],
      "source": [
        "# we can see that the word \"dog\" is associated with eight different synsets.\n",
        "wn.synsets('dog')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yG1t06PrnGO"
      },
      "source": [
        "Each synset is a word or set of words associated with a specific meaning (which are referred to as *senses*). In the output above, we can see that the word `dog` is included in eight different synsets.\n",
        "\n",
        "\n",
        "This means that WordNet includes eight possible meanings (or senses) for which the word `dog` can be associated. The actual names of the synsets are provided in this format:\n",
        "\n",
        "```\n",
        "word.x.01\n",
        "```\n",
        "\n",
        "`word.` — the \"main\" word associated with the synset.\n",
        "\n",
        "`.x.` — the part of speech   \n",
        "  - (above we see `n` and `v` for `noun` and `verb`)\n",
        "\n",
        "`01` — this is how they maintain repeats of the same synset name and also indicate the most common uses.\n",
        "  - this means whatever meaning or sense is associated with `dog.n.01` is thought to be more frequent than `dog.n.03`.\n",
        "\n",
        "So, inspecting the output above there are eight synsets. Two synsets have dog as the \"main\" word (`dog.n.01` and `dog.n.03`), whereas the other six synsets will include `dog` as word associated with the synset meaning.\n",
        "\n",
        "\n",
        "Let's save the first synset to a variable and explore the information contained within:\n",
        "\n",
        "CAREFUL!\n",
        "\n",
        "- Note that we use `synsets()` to find all synsets with a string word as input (synset**S**)\n",
        "\n",
        "- We use `synset()` to call a specific synset using the name of the synset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7WE5XDzs-Mm"
      },
      "outputs": [],
      "source": [
        "# when you know the name of a synset you can call it directly\n",
        "# save the dog synset to a variable.\n",
        "dog01 = wn.synset('dog.n.01')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivziZ5S_O1Vu"
      },
      "source": [
        "There are a number of method functions we can use. Two that are helpful to understand synsets are these:\n",
        "\n",
        "- `.lemma_names()` — the other words which have the same meaning/sense (i.e., other words in the same synset)\n",
        "- `.definition()` — the full definition of the synset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXlmF-GDryxy"
      },
      "outputs": [],
      "source": [
        "# use lemma_names() to see all the other words in a synset\n",
        "# this helps us understand the \"meaning\" of the first synset for dog\n",
        "dog01.lemma_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_eL7VgMPGbx"
      },
      "outputs": [],
      "source": [
        "# use .definition() to get the actual meaning\n",
        "# this meaning makes sense right?\n",
        "dog01.definition()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvyrk_GqPNYB"
      },
      "source": [
        "So `dog.n.01` is related to the domestic animal, and the words / phrases `domestic_dog` and `canis_familiaris` are thought to be approximately equivalent in meaning/sense. That makes...sense...right?\n",
        "\n",
        "Let's explore the other synset with `dog` in the name, `dog.n.03`. There is only one word in the lemma names, suggesting this is a very specific use of the word dog:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naETXbVttP0D"
      },
      "outputs": [],
      "source": [
        "# lemma names\n",
        "wn.synset('dog.n.03').lemma_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCWQotBptjAF"
      },
      "outputs": [],
      "source": [
        "# oh...this is clearly a different meaning!\n",
        "wn.synset('dog.n.03').definition()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MXgeoSFPjVK"
      },
      "source": [
        "So the other meaning of \"dog\" is a colloquialism with a very specific meaning. Again, there are no other words (or lemmas) included in this synset, further exhibiting the specific meaning associated with this use of dog.\n",
        "\n",
        "What about the other synsets? Each of them was returned because the word \"dog\" is a lemma in the synsets.\n",
        "\n",
        "\n",
        "For example, the `frank.n.02` synset meaning is related to hot dogs or frankfurters, and `dog` is one of the lemmas listed as a possible synonym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb_fgcJgRTRb"
      },
      "outputs": [],
      "source": [
        "wn.synset('frank.n.02').lemma_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWriX48TRMl7"
      },
      "outputs": [],
      "source": [
        "wn.synset('frank.n.02').definition()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epSomDIiRrJa"
      },
      "source": [
        "### Better understanding how synsets are accessed\n",
        "\n",
        "> *(I found this out by accident when playing around and thought it was fun to share)*\n",
        "\n",
        "You can explore the other meanings and definitions by calling synset names as they were provided above.\n",
        "\n",
        "Alternatively, since we know there are seven total synsets which include `dog` as a `noun`, we can iterate through those synsets by calling `dog.n.0x`, where `x` is the number 1-7.\n",
        "\n",
        "I demonstrate this below using a loop which ranges through the numbers 1-7 and then calls the synset using `dog.n.0x` instead of the names provided above.\n",
        "\n",
        "This helps us see that the number in the synset is related to the frequency of use of a word's different meanings, as well as the flexibility associated with calling synsets!\n",
        "\n",
        ">> *In the cell you will see that to cycle through 1-7, I need to call `range(1,8)`.This is similar to slicing, in that I am asking for everything starting at 1 and ending at 8, but this does **not** include 8. I encourage you to play around with `range()` in order to better understand how this works*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQDXSce0R7wb"
      },
      "outputs": [],
      "source": [
        "# (how could this loop be changed to account for words that have more than 10 synsets?)\n",
        "# (how could you make a function which can print out the synsets regardless of their length?\n",
        "# # how could you always know the size of the synset?)\n",
        "\n",
        "for i in range(1,8):\n",
        "  print('definition: ' + str(i))\n",
        "  print(wn.synset('dog.n.0' + str(i)).definition())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADvcqhLcUUl5"
      },
      "outputs": [],
      "source": [
        "# we can also see what happens when we call a synset beyond the range (check out the WordNetError)\n",
        "wn.synset('dog.n.08')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12NyGVKzVoRd"
      },
      "source": [
        "This makes perfect sense, because if you recall, we started this whole search by searching for the word \"dog\" and saw that there were eight synsets, seven of which were associated with nouns. So if we wanted to know how many \"meanings\" or \"senses\" are associated with a word, we can query the total number of synsets returned for a word, regardless of the name of the synset.\n",
        "\n",
        "Just as a fun exercise, consider the function below where I use this information to make a smarter function which will tell us all the basic information that we might want to know for different words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4luaillGwu3E"
      },
      "outputs": [],
      "source": [
        "# because you can use len to find how many senses a word has...\n",
        "len(wn.synsets('dog'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhV9-VWcwu3E"
      },
      "outputs": [],
      "source": [
        "# and because you could use the `.pos()` method to find the POS uses...\n",
        "for synset in wn.synsets('dog'):\n",
        "    print(synset.pos())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "howrUjYlwu3F"
      },
      "outputs": [],
      "source": [
        "#  you could write a function to automatically count and print various information about words\n",
        "def print_my_synsets_please(target):\n",
        "    synsets = wn.synsets(target)\n",
        "\n",
        "    # only do this stuff if there are any synsets for the target\n",
        "    if synsets:\n",
        "\n",
        "        # create variables to count number of POS uses for the word\n",
        "        nouns = 0\n",
        "        verbs = 0\n",
        "        adjs = 0\n",
        "\n",
        "        # iteratively add to each pos as you find them\n",
        "        for synset in synsets:\n",
        "            if synset.pos() == 'n':\n",
        "                nouns += 1\n",
        "            if synset.pos() == 'v':\n",
        "                verbs += 1\n",
        "            if synset.pos() == 'a':\n",
        "                adjs += 1\n",
        "\n",
        "        # save all the synsets for different POS\n",
        "        noun_synsets = [synset.definition() + '\\n' for synset in synsets if synset.pos() == \"n\"]\n",
        "        verb_synsets = [synset.definition() + '\\n' for synset in synsets if synset.pos() == \"v\"]\n",
        "        adj_synsets = [synset.definition() + '\\n' for synset in synsets if synset.pos() == \"a\"]\n",
        "\n",
        "        # print out total number of senses, then number of senses for each POS along with their definitions\n",
        "        # only print info for POS if they have senses for that POS\n",
        "\n",
        "        print(f'Target {target} has {len(synsets)} senses.')\n",
        "        if nouns > 0:\n",
        "            print(f'Nouns: {nouns}')\n",
        "            for n in noun_synsets:\n",
        "                print(n)\n",
        "\n",
        "        if verbs > 0:\n",
        "            print(f'Verbs: {verbs}')\n",
        "            for v in verb_synsets:\n",
        "                print(v)\n",
        "\n",
        "        if adjs > 0:\n",
        "            print(f'Adjectives: {adjs}')\n",
        "            for a in adj_synsets:\n",
        "                print(a)\n",
        "    else:\n",
        "        print(f'Sorry, target word {target} makes no sense!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_UY-aDvwu3F"
      },
      "source": [
        "Since I've gone to all that trouble making this function, try it out on some words to see how it works!\n",
        "\n",
        "If you're brave, try it on the word `run`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cgCMWsgwu3F"
      },
      "outputs": [],
      "source": [
        "print_my_synsets_please('dog')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_gIxonywu3F"
      },
      "outputs": [],
      "source": [
        "print_my_synsets_please('Canada')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxKmyQX7wu3F"
      },
      "outputs": [],
      "source": [
        "print_my_synsets_please('happy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkTmxUIUwu3G"
      },
      "outputs": [],
      "source": [
        "print_my_synsets_please('comb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syeXM6dRwu3G"
      },
      "outputs": [],
      "source": [
        "print_my_synsets_please('blarg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqKbjVZiwu3G"
      },
      "source": [
        "What other helper functions might you want to make for WordNet? Or, how else you you update this function to allow for more options / customization?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-aNjID5VGmy"
      },
      "source": [
        "### Specify part of speech in WordNet searches\n",
        "\n",
        "We now know that we can use `.pos()` to check the POS of specific synsets, but we can also specify specific parts of speech when querying WordNet. You can do so by using the `pos = ` argument in `wn.synsets()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl4BqA2OVZMX"
      },
      "outputs": [],
      "source": [
        "# only return synsets that are nouns\n",
        "wn.synsets('dog', pos = 'n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69x9kT3jVyW1"
      },
      "source": [
        "So we can quickly count specific meanings for different types if we need — could this information be used to modify the function I wrote above?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7E7SWqQV04X"
      },
      "outputs": [],
      "source": [
        "# how many meanings does 'dog' have as a noun?\n",
        "len(wn.synsets('dog', pos = 'n'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmrU0ptBWG2I"
      },
      "outputs": [],
      "source": [
        "# how many meanings does 'dog' have as a verb?\n",
        "len(wn.synsets('dog', pos = 'v'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0mffmRiQSWB"
      },
      "source": [
        "### Double-check the online version of WordNet\n",
        "\n",
        "Take a moment now to go to the [online version of WordNet](http://wordnetweb.princeton.edu/perl/webwn). Type in the word 'dog' and search for it. You should see the same information we've explored here, but presented in a graphical user interface rather than using Python as we have in this notebook. This may help you get a better understanding of how the WordNet information is stored.\n",
        "\n",
        "After using the website, consider the pros/cons of using Python and NLTK to do effectively the same thing. Being able to search WordNet programatically will be more efficient than looking up words one-at-a-time in the website version. At the same time, using the website version might make it easier to see the larger connections and categories when compared to accessing the information through NLTK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU0Hz5j0t5TZ"
      },
      "source": [
        "### **Your Turn**\n",
        "\n",
        "Explore some other words in WordNet to get a hang of looking through different synsets and accessing the information within. You should try the following **your turn** prompt:\n",
        "\n",
        "> *Your Turn: Write down all the senses of the word `dish` that you can think of. Now, explore this word with the help of WordNet, using the same operations we used above.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOHBBMait-LC"
      },
      "outputs": [],
      "source": [
        "# look through other synsets here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii9feFqTuIKj"
      },
      "source": [
        "## Hypernyms and Hyponyms\n",
        "\n",
        "\n",
        "So, the `synsets` show groups of words with approximately similar meanings — in this manner, these words are related to one another (through shared and similar senses). Another way words can relate to one another is through hierarchical categorization. For example, some words are larger categories for other words — the word `vehicle` is a larger category which can include `car`, `ambulance`, `truck`, and so one, while `car` is itself a larger category which can contain terms like `sedan`, `hatchback`, and so on.\n",
        "\n",
        "These sorts of categorical relationships are known as **hypernymy** and **hyponymy**. WordNet includes this information for all of the words in WordNet, allowing you to traverse higher-level and lower-level cateogries associated with particular words.\n",
        "\n",
        "The two key terms are **hypernym** and **hyponym**.\n",
        "\n",
        "> HYPER means *above*, and HYPO means *below*.\n",
        "\n",
        "Whether any one word is a hypernym or hyponym is always relative and depends on the word you are starting from. Using the example above of vehicles, we could say that `vehicle` is a hypernym of `car`, while `car` is a hypernym of `hatchback`. Conversely, `car` is a hyponym of `vehicle`. So, again, the designation of hypernym vs. hyponym comes down to which word one starts with, and which direction through the categories one wishes to traverse.\n",
        "\n",
        "We can access the hypernyms of hyponyms of words using the `.hypernyms()` and `.hyponyms()` methods from the `synset` objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95lVCAQezLlo"
      },
      "outputs": [],
      "source": [
        "# which categories are smaller (more specific) than \"dog\"?\n",
        "# inspect the results - are these all more specific types of dogs?\n",
        "dog01.hyponyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goYTRhCwzaGA"
      },
      "outputs": [],
      "source": [
        "# which categories are larger (less specific) than \"dog\"?\n",
        "# inspect the results - are these categories larger than dog? Would they have additional members besides dog?\n",
        "dog01.hypernyms()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1E4ryVsz4FU"
      },
      "source": [
        "Again, you can think of the hypernyms and hyponyms as different levels up or down a hierarchy. And, because we can quantify the number of levels or steps between two words/senses, we can calculate an approximation of the distance and/or similarity among concepts associated with the words. For example, what are the hypernyms of `dog` and `wolf`?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3yY9UjLwu3I"
      },
      "outputs": [],
      "source": [
        "# compare hypernyms of dog and wolf\n",
        "print(f'Dog hypernyms: {wn.synset(\"dog.n.01\").hypernyms()}\\n\\nWolf hypernyms: {wn.synset(\"wolf.n.01\").hypernyms()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKpYF6TZwu3I"
      },
      "source": [
        "Ah ha! We can see that `dog` and `wolf` both include `canine.n.02` as a hypernym. Inspecting that synset gives us the definition:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emGYpM3Fwu3I"
      },
      "outputs": [],
      "source": [
        "wn.synset('canine.n.02').definition()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K4z1VUVwu3I"
      },
      "source": [
        "And running `.hyponyms()` on that synset naturally includes `dog` and `wolf`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfSsel4qwu3I"
      },
      "outputs": [],
      "source": [
        "# that first one is a doozy - run the `.definition()` to find out it refers specifically to female dogs\n",
        "wn.synset('canine.n.02').hyponyms()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiE2TWuGwu3I"
      },
      "source": [
        "So, we can see that `dog` and `wolf` are immediate members of the same hypernym (i.e., `canine`), which suggest these words are conceptually and semantically related. At the same time, there are seven total immediate members of the category `canine`, meaning that these seven terms/words/concepts/senses are relatively similar (because they are at an equal level under a hypernym).\n",
        "\n",
        "What do you think? We know that a fox, a wolf, and a dog are clearly different. But we know they are *similar*, and this this categorization captures some approximation of that similarity.\n",
        "\n",
        "Do you think this categorization reflects the way that humans categorize objects/concepts through language?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNshCnQtwu3I"
      },
      "source": [
        "### Calculating specificity through hypernym/hyponym pathways\n",
        "\n",
        "Based on where a word is in relative to other words in the WordNet heirarchy, that word may be associated with a very specific or very general concept. And, there may be different pathways to different higher-level concepts, depending on how similar the word is to other words. No matter what word you start with, there are higher level nodes that represent the \"end\" of many concepts.\n",
        "\n",
        "Several people have mapped this relationship, for example [this paper](https://www.semanticscholar.org/paper/Inductive-learning-of-lexical-semantics-with-typed-Kazakov-Dobnik/e46c008c3b83b9a0155d7f8a5319a1208d8922ae) provided this figure:\n",
        "\n",
        "<img src = https://i.imgur.com/eKr5Zfh.jpg width = \"800\" height = \"350\">\n",
        "\n",
        "You can see on this graphic the highest level node linking all of the lower-level nodes is `entity`. There are no hypernyms for `entity`, only hyponyms. Inspecting the definition of entity reveals a very broad and general category, making it a good fit for one of the highest-level concepts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8vHUrBjwu3I"
      },
      "outputs": [],
      "source": [
        "wn.synset('entity.n.01').definition()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOFE8ASqwu3J"
      },
      "source": [
        "We can explore relative distances among words/concepts in WordNet using these paths.\n",
        "\n",
        "Specifically, the `.hypernym_paths()` method lets you explore these paths. For `dog`, because there are two *immediate* hypernyms (`domestic_animal` or `canine`), there are two possible routes or pathways to a higher-level category (both eventually end at `entity`). Depending on which of these two paths you take, different higher-level categories will be traversed. Remember that `wolf` only had one hypernym, and thus has only one immediate route to a higher level category.\n",
        "\n",
        "Examine the two hypernym paths below, you should see how the categories become less specific as one goes up the list. Also note that the end hypernym is the same for both paths.\n",
        "\n",
        "When starting at the bottom, you should be able to use the `\"is a\"` method for moving up the list. A dog is a canine, a canine is a carnivore, etc...\n",
        "\n",
        "As we will see later on, this function counts the number of paths between two words to approximate their similarity - neat!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytoH9qTw0SGn"
      },
      "outputs": [],
      "source": [
        "# save the hypernym paths of dog.n.01\n",
        "dog_paths = dog01.hypernym_paths()\n",
        "\n",
        "# how many paths are there?\n",
        "# (read the paths from the bottom to the top, noting there are two separate entries for dog)\n",
        "len(dog_paths)\n",
        "\n",
        "dog_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5cRS5w00tr6"
      },
      "outputs": [],
      "source": [
        "# look at the first path (read from the bottom up)\n",
        "# a dog is a canine is a carnivore is a placental...(and so on)\n",
        "dog_paths[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8mNok5E0w_8"
      },
      "outputs": [],
      "source": [
        "# look at the second path (read from the bottom up)\n",
        "# a dog is a domestic animal is an animal is an organism...(and so on)\n",
        "dog_paths[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS349sPH23FN"
      },
      "source": [
        "## **Semantic Similarity**\n",
        "\n",
        "There are a number of computational ways to calculate semantic similarity, and they usually rely on capturing some sort of mathematical \"distance\" between words.\n",
        "\n",
        "Semantic spaces built from word vectors using Latent Semantic Analysis (LSA) or word2vec can do this too, but WordNet demonstrates this idea using distance in terms of categories, which is related more to human conceptualisations of word meaning, rather than word distributions.\n",
        "\n",
        "In all cases, greater distance arguably means that something is less similar when compared to shorter distance.\n",
        "\n",
        "In WordNet, the distance between two words and a root hypernym or hyponym is taken as a measure of similarity. So, the hypernym/hyponym relationship is used to calculate this measure of similarity.\n",
        "\n",
        "In the example from the book, several different synsets are saved as variables, some of which logically are more related than others.\n",
        "\n",
        "The authors then demonstrate the similarity among these saved synsets out.\n",
        "\n",
        "I have always found it confusing the authors used \"right\" as a variable name without explaining it, but it refers to a type of whale: [a right whale](https://en.wikipedia.org/wiki/Right_whale).\n",
        "\n",
        "I added the `.definition()` method for each version below so you can get an idea as to why the authors are using these examples for the test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6ZobAdjUYhB"
      },
      "outputs": [],
      "source": [
        "orca = wn.synset('orca.n.01')\n",
        "orca.definition()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eQzuZ8hUYji"
      },
      "outputs": [],
      "source": [
        "minke = wn.synset('minke_whale.n.01')\n",
        "minke.definition()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bbBWBTFUYmM"
      },
      "outputs": [],
      "source": [
        "right = wn.synset('right_whale.n.01')\n",
        "right.definition()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEJkS2hoUbZC"
      },
      "outputs": [],
      "source": [
        "tortoise = wn.synset('tortoise.n.01')\n",
        "tortoise.definition()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slmgYIzsUdV-"
      },
      "outputs": [],
      "source": [
        "novel = wn.synset('novel.n.01')\n",
        "novel.definition()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoU1GqXnVRBa"
      },
      "source": [
        "The `lowest_common_hypernm()` method will find the closest hypernym which two synsets share. Remember, hypernyms are the higher-level categories. So if two words share the next highest-level category (such as wolf and dog), they will be more similar than words which only share the most highest-level category, such as `entity.`\n",
        "\n",
        "If a hypernym is \"lower\" that means it is more specific because it is lower in the overall categorisation schema - so two words linked by a more specific hypernym are more simliar than if they are linked by an abstract hypernym (such as entity). You can see the WordNet explanation [here](https://www.nltk.org/api/nltk.corpus.reader.wordnet.html?highlight=lowest_common_hypernyms#nltk.corpus.reader.wordnet.Synset.lowest_common_hypernyms)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnuur1OYUWjT"
      },
      "outputs": [],
      "source": [
        "# what is the lower common hypernym of right whales and minke whales?\n",
        "right.lowest_common_hypernyms(minke)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtwxQJUPU-rK"
      },
      "outputs": [],
      "source": [
        "# lowest common hypernym of right whale and orcas?\n",
        "right.lowest_common_hypernyms(orca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAt7zJnFVu4N"
      },
      "source": [
        "So which pair is more similar? Right Whales and Minke Whales are linked by Baleen Whale. Right Whales and Orcas are linked by Whale. Since a Baleen Whale is more specific than the term Whale, Right Whales and Minke Whales are more similar than Right Whales and Orcas. At least, that is the logic of these relationships.\n",
        "\n",
        "Continue the exercise to compare right whales to tortoises and novels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w80zVl6hU-uC"
      },
      "outputs": [],
      "source": [
        "# vertebrate is less specific when compared to 'whale'\n",
        "# so they are less similar than the comparisons done above.\n",
        "right.lowest_common_hypernyms(tortoise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1mBeHD_WEnB"
      },
      "outputs": [],
      "source": [
        "# entity is the least specific category possible,\n",
        "# so right whales and novels have almost no semantic similarity.\n",
        "right.lowest_common_hypernyms(novel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kXTU2qLWYDG"
      },
      "source": [
        "Now that you conceptually understand the way NLTK defines these measures of similarity and difference, you can use the `.similarity()` methods to see the numeric measure WordNet will return.\n",
        "\n",
        "Remember that `right` refers to a type of whale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACEdxwsWWmcf"
      },
      "outputs": [],
      "source": [
        "# finds the shortest path with connects two things - higher number = more similar\n",
        "right.path_similarity(minke)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo9tO863WsEm"
      },
      "outputs": [],
      "source": [
        "# less similar..\n",
        "right.path_similarity(orca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjdBmUOZWsHq"
      },
      "outputs": [],
      "source": [
        "# even less similar...\n",
        "right.path_similarity(tortoise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGZnNXXQWsKo"
      },
      "outputs": [],
      "source": [
        "# even more less similar!...\n",
        "right.path_similarity(novel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMRJhKQsXCRl"
      },
      "source": [
        "Let's look at some other examples. Try it out for yourself, what other examples do you want to look at?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8D2QX-vXTtU"
      },
      "outputs": [],
      "source": [
        "# compare dog and cat\n",
        "wn.synset('dog.n.01').path_similarity(wn.synset('cat.n.01'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-OxGK7PhhU9"
      },
      "source": [
        "Hopefully you're at the point where you think writing a function is a better way to explore new resources. I've written a helper function below to make it faster for us to compare similarities between inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ilIOL_UXfHH"
      },
      "outputs": [],
      "source": [
        "# why not write a short helper function?\n",
        "\n",
        "def compare_similarity(base, comparison):\n",
        "  \"\"\"compares two WordNet synsets\"\"\"\n",
        "  print(f'{base} & {comparison}: {base.path_similarity(comparison)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AqsinfWXlxb"
      },
      "outputs": [],
      "source": [
        "# define a baseline for comparison\n",
        "base = wn.synset('beer.n.01')\n",
        "\n",
        "# you can add any number of synsets here\n",
        "comparisons = [wn.synset('wine.n.01'), wn.synset('water.n.01'), wn.synset('bread.n.01'),\n",
        "               wn.synset('alcohol.n.01'), wn.synset('whiskey.n.01'), wn.synset('juice.n.01'),\n",
        "               wn.synset('vegetable.n.01')]\n",
        "\n",
        "# loop through comparisons and compare all to base.\n",
        "for compare in comparisons:\n",
        "  compare_similarity(base, compare)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIZC9ZiNDbJH"
      },
      "source": [
        "## **Meronyms and Holonymns**\n",
        "\n",
        "In addition to larger/smaller categories, words can also be related in terms of being parts of a whole or a whole comprised of parts. Wikipedia has a pretty good explanation of this [here](https://en.wikipedia.org/wiki/Meronymy_and_holonymy).\n",
        "\n",
        "For example, we can see the words which are all thought to have meanings that are related to different components of what a tree is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oir1pIMD7QK"
      },
      "outputs": [],
      "source": [
        "# what are smaller ideas contained with the larger idea of tree?\n",
        "wn.synset('tree.n.01').part_meronyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovo7ZKepEvZU"
      },
      "outputs": [],
      "source": [
        "# this is kinda weird, what's going on here?\n",
        "# what are the smaller \"ideas\" or \"concepts\" contained within \"dog\"?\n",
        "wn.synset('dog.n.01').part_meronyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2EgrYXyE-0s"
      },
      "outputs": [],
      "source": [
        "# oh...weird?\n",
        "wn.synset('flag.n.07').definition()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie0LMG06FKUq"
      },
      "outputs": [],
      "source": [
        "# how about the word planet? what might we find?\n",
        "wn.synsets('planet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrssfSKaFeMX"
      },
      "outputs": [],
      "source": [
        "# is this part of a planet?\n",
        "wn.synset('planet.n.01').part_meronyms()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEpExDgmF49B"
      },
      "source": [
        "WordNet also has a way to find the \"subtance\" of something, which is slightly different than the component parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7PKolppEcj7"
      },
      "outputs": [],
      "source": [
        "wn.synset('tree.n.01').substance_meronyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5QftWPuKkvN"
      },
      "outputs": [],
      "source": [
        "# I think the water example makes it a bit easier to see what substance/part is doing.\n",
        "wn.synset('water.n.01').substance_meronyms()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa5TTygLNwdv"
      },
      "source": [
        "We can then use `member_holoynms()` and `substance_holonyms()` methods to go the other direction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxjNCfYBEcrn"
      },
      "outputs": [],
      "source": [
        "# trees are members of forests\n",
        "wn.synset('tree.n.01').member_holonyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhVrBxegN7h9"
      },
      "outputs": [],
      "source": [
        "# water is the subtance for plenty of things.\n",
        "wn.synset('water.n.01').substance_holonyms()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNzr719ykI7U"
      },
      "source": [
        "The NLTK book makes the point that these different relationships demonstrate the intertwined nature of words and concepts (i.e., like a net!). The book demonstrates this first by looking at the synsets for the word \"mint\", and then how those synsets are further related to each other through associations such as meronyms etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfqNh-LJOIC7"
      },
      "outputs": [],
      "source": [
        "# note that you can specify a string and a POS for WordNet to search.\n",
        "for synset in wn.synsets('mint', pos = 'n'):\n",
        "  print(synset.name() + ':', synset.definition())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OwD2lEHOanV"
      },
      "source": [
        "The point being made here is that NLTK wants you to see how intertwined synsets are. Different senses of `mint` might in turn reflect these part:whole relationships"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbxDa89tOMA7"
      },
      "outputs": [],
      "source": [
        "wn.synset('mint.n.04').part_holonyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N574RlyDOXWw"
      },
      "outputs": [],
      "source": [
        "wn.synset('mint.n.04').substance_holonyms()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB6-XMU2L6WU"
      },
      "source": [
        "There are quite a few other things you can do with WordNet not explained in NLTK - look [here](https://www.nltk.org/howto/wordnet.html)\n",
        "\n",
        "Although there are a range of other methods, not all words / synsets have the same info available and it can be a pain figuring this out. For example, below I use the `derivationally_related_forms()` method (which is not explained in the book), but this function has to be run on a lemma, not a sysnet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6v54mAKLeEa"
      },
      "outputs": [],
      "source": [
        "# find all the different ways the word \"happy\" can be derived\n",
        "wn.synset('happy.a.01').lemmas()[0].derivationally_related_forms()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZolxxesIMY34"
      },
      "source": [
        "There is also a useful function `.antonyms()` which provide synsets with opposite meanings. You likely noticed the synsets here have `.a.` as the part of speech, which means they are adjectives. In English, adjectives are words which can be more productively derived as well as have more straightforward oppossites, so it makes sense that these functions are seemingly specific to adjectives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brZZbYKnMLiA"
      },
      "outputs": [],
      "source": [
        "# if you're not happy, you're...\n",
        "wn.synset('happy.a.01').lemmas()[0].antonyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGoLAPzLNaJ6"
      },
      "outputs": [],
      "source": [
        "# why is it difficult for nouns to have opposites compared to adjectives?\n",
        "# there is no \"opposite\" for dog, right? (it would be something like \"undog\")\n",
        "wn.synset('dog.n.01').lemmas()[0].antonyms()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BgkaxEbD1V9"
      },
      "source": [
        "## **Verb Entailment**\n",
        "\n",
        "Another interesting concept to explore in WordNet is the concept of **verb entailment**. Roughly speaking, entailment is a logical deduction based on how different verbs relate to one another, sort of in a cause-and-effect relationship. For example, being punched also means being hurt, swimming also means becoming wet, and so on. The example from the book is that walking entails stepping.\n",
        "\n",
        "I've found all the words I think up usually have no entailment!\n",
        "\n",
        "But you should play around and see what you can find :)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa7POt8W2C0D"
      },
      "outputs": [],
      "source": [
        "# What other entailments can you think of and test?\n",
        "wn.synset('practice.v.01').entailments()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ud9dyyxwu3O"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "WordNet represents a really interesting way to start thinking about how we can computationally measure a word's \"meaning.\" If you think about it, the `.definition()` function of WordNet is likely very useless as a computational measure (unless we can somehow parse the text of the definition!). By quantifying the space between words and concepts, WordNet provides an interesting and useful (if imperfect) measure of semantic distance and associations.\n",
        "\n",
        "There are other \"nets\" included in NLTK, such as VerbNet and the Multilingual WordNet. If you're keen, you can explore them in the NLTK docs:\n",
        "\n",
        "- [VerbNet](https://www.nltk.org/api/nltk.corpus.reader.verbnet.html?highlight=verb%20net#module-nltk.corpus.reader.verbnet)\n",
        "- [FrameNet](https://www.nltk.org/api/nltk.corpus.reader.framenet.html?highlight=frame%20net#module-nltk.corpus.reader.framenet)\n",
        "- [Multilingual WordNet](https://github.com/globalwordnet/OMW) - (I don't know if you can access this through NLTK but I think you can, might need to search for \"omw\" which stands for open multilingual wordnet)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "U0mffmRiQSWB"
      ],
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "44a9cdcbdccbf05a880e90d2e6fe72470baab4d1b82472d890be0596ed887a6b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}